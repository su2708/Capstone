아나콘다 프롬프트 실행
conda create -n yolo
cd C:\yolov5\
pip install -r requirements.txt
cat dataset\data.yaml
python detect.py --source 0 --img 160
종료 : q 연타


방법1
실제 주행하면서 영상자료 얻음
프레임 단위로 캡쳐해서 dataset (이미지 파일)생성 (대략 300개 이상이면 ㄱㅊ음)
생성한 이미지 파일들 roboflow에서 바운딩 박스 직접 만들어서 라벨링
그렇게 생성한 dataset으로 colab에서 학습시킨 후 가중치 best.pt 획득
코랩에서 학습한 가중치 사용해 로컬 웹캠으로 적용
=>가장 좋으나 귀찮음
(우리나라 도로 자료로 최적화 가능)


방법2
데이터셋 파일 구해서 그거 이어 붙인후(차량,보행자,신호등)
코랩에서 train.py로 학습시키기 
단점 :데이터셋 구림
=>우리나라 차량 별로없고 데이터셋 상태가 이미지 돌려씀)


방법3
이미 되는 가중치파일 구해서 그거 넣고 detect.py실행
잘될시 그냥 쓰기
단점 :그냥 돌아가는 코드 갖다 쓰기..?







차량 위험 거리 알고리즘 
앞차를 감지했을때 
1.바운딩 박스의 넓이가 일정 이상일때 
2.바운딩 박스의 넓이가 점점 증가할때
경고 신호 (ex 주차할때 처럼 띠띠띠띠)

보행자의 경우도 마찬가지


해야하는 과정
yolov5는 학습시키는 과정이 한번에 학습시켜야함
결국 새로운 이미지 등을 '추가'적으로 학습시키고 싶으면, 
'추가된 이미지'와 '기존의 이미지'에 대하여 다시 처음부터 학습을 돌리는 수 밖에 없다. 
(말 그대로 '이어서' 학습은 가능하나, '붙여서' 학습하기가 안 된다. )
목적=> 차량, 보행자 , 신호등 dataset 을 만든다

1.주행하는 영상 자료를 프레임 캡쳐해서 바운딩박스 치고 roboflow에 저장, 라벨링
2.yolov5의 detect.py 를 수정해서 실시간 영상에서 오브젝트를 감지했을때 
감지한 클래스와 바운딩 박스의 넓이를 return
3.(라즈베리파이내의)main 함수에서 영상 출력시 바운딩 박스표시(detect.py에 있음)
+일정크기이상의 바운딩박스에서 지속적으로 증가하는지 감지시 알람출력하는거 구현

할일
차량 주행 영상파일 확보(유투브..등등) 
프레임 단위 캡쳐 총 400장 정도
한 이미지에서 차량, 보행자 , 초록신호등, 빨강신호등 
4개의 클래스로 바운딩 박스 라벨링



